# global settings
logs_dir: './lightning_logs'
seed: 42
run_name: esrgan

# visualization settings
n_vis_images: 4
vis_frequency: 30

# dataset settings
num_workers: 0
dataset_dir: './data/text_zoom'
hr_img_size: !!python/tuple [64, 256] # hxw
scale_factor: 2
val_split_complexity: easy
test_split_complexity: medium
shuffle: True

norm_means: [0.0, 0.0, 0.0]
norm_stds: [1.0, 1.0, 1.0]

# train settings
batch_size: 8
optimizers: 
  - # generator's optimizer
    type: torch.optim.Adam
    lr: 0.0002
  - # discriminator's optimizer
    type: torch.optim.Adam
    lr: 0.0002

schedulers:
  - # generator's scheduler
    type: torch.optim.lr_scheduler.MultiStepLR
    milestones: [8, 16, 24, 32]
    gamma: 0.5
  - # discriminator's scheduler
    type: torch.optim.lr_scheduler.MultiStepLR
    milestones: [8, 16, 24, 32]
    gamma: 0.5

ckpt_path: null

model:
  type: ESRGAN
  num_rrdb_blocks: 11
  warmup_iters: 1 # how many iters to train only generator with pixel loss

trainer:
  type: pytorch_lightning.Trainer
  max_epochs: 40
  gpus: 1
  track_grad_norm: 2
  log_every_n_steps: 50
  precision: 32
  resume_from_checkpoint: './saved_models/epoch=0-step=2170.ckpt'
